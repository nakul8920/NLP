{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71eb0f87",
   "metadata": {},
   "source": [
    "# 1. Create a Doc object from the file owlcreek.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f89364da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "with open('owlcreek.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "doc = nlp(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877c9be5",
   "metadata": {},
   "source": [
    "# 2. How many tokens are contained in the file?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f094d93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4835"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of tokens in the file\n",
    "num_tokens = len(doc)\n",
    "num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938c402c",
   "metadata": {},
   "source": [
    "# 3. How many sentences are contained in the file?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6798e243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of sentences\n",
    "num_sentences = len(list(doc.sents))\n",
    "num_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a50b61",
   "metadata": {},
   "source": [
    "# 4. Print the second sentence in the document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c413dbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The man's hands were behind\n",
      "his back, the wrists bound with a cord.  \n"
     ]
    }
   ],
   "source": [
    "# Print the second sentence\n",
    "sentences = list(doc.sents)\n",
    "second_sentence = sentences[1]\n",
    "print(second_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d7249c",
   "metadata": {},
   "source": [
    "# 5. For each token in the sentence above, print its text, POS tag, dep tag and lemma.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca87238a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The          DET    det                    the\n",
      "man          NOUN   poss                   man\n",
      "'s           PART   case                   's\n",
      "hands        NOUN   nsubj                  hand\n",
      "were         AUX    ROOT                   be\n",
      "behind       ADP    prep                   behind\n",
      "\n",
      "            SPACE  dep                    \n",
      "\n",
      "his          PRON   poss                   his\n",
      "back         NOUN   pobj                   back\n",
      ",            PUNCT  punct                  ,\n",
      "the          DET    det                    the\n",
      "wrists       NOUN   appos                  wrist\n",
      "bound        VERB   acl                    bind\n",
      "with         ADP    prep                   with\n",
      "a            DET    det                    a\n",
      "cord         NOUN   pobj                   cord\n",
      ".            PUNCT  punct                  .\n",
      "             SPACE  dep                     \n"
     ]
    }
   ],
   "source": [
    "for token in second_sentence:\n",
    "        print(f'{token.text:{12}} {token.pos_:{6}} {token.dep_:<{22}} {token.lemma_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb3d1c8",
   "metadata": {},
   "source": [
    "# 6. Write a matcher called 'Swimming' that finds both occurrences of the phrase \"swimming vigorously\" in the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "913a9a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "pattern = [{\"LEMMA\": \"swim\"}, {\"LOWER\": \"vigorously\"}]\n",
    "matcher.add(\"Swimming\", [pattern])\n",
    "matches = matcher(doc)\n",
    "matches\n",
    "\n",
    "for match_id, start, end in matches:\n",
    "    matched_span = doc[start:end]\n",
    "    print(f\"Match found: {matched_span.text}, Start: {start}, End: {end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb80ad0",
   "metadata": {},
   "source": [
    "# 7. Print the text surrounding each found match.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34553e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text surrounding each 'swimming vigorously' match:\n"
     ]
    }
   ],
   "source": [
    "surrounding_text = []\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start-5:end+5]  # 5 tokens before and after\n",
    "    surrounding_text.append(span.text)\n",
    "\n",
    "print(\"Text surrounding each 'swimming vigorously' match:\")\n",
    "for text in surrounding_text:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db37ffbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
